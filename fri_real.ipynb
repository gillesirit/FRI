{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing FRI\n",
    "Author: Gilles Richard\n",
    "Date  : 2023\n",
    "The program for the candidate paper \"FEATURE RELEVANCE INDEX\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 1: Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code is an implementation of FRI, supposed to overcome the curse of dimensionnality faced by ARI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install matplotlib pandas sklearn statistics sklearn_relief\n",
    "import numpy as np\n",
    "from math import *\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "\n",
    "# FOR CHI-SQUARE - MUTUAL INFORMATION - RELIEF\n",
    "from sklearn.feature_selection import chi2,mutual_info_classif\n",
    "import sklearn_relief as relief\n",
    "from skrebate import ReliefF\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# FOR CROSS FOLD VALIDATION\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# FOR TESTING ON LOGISTIC REGRESSION\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "# where all utilities are defined\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 2: Dataset generation, pair generation and sampling in data_generation.py\n",
    "## ACTION 3: Baseline logistic regression, decision trees, random forests in baseline.py\n",
    "## ACTION 4: FRI utilities in fri.py\n",
    "## ACTION 5: Display functions for latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_k_best_feature(dimension,row_name,feature_list,k):\n",
    "    latex_line=\"\"\n",
    "    for i in range(k):\n",
    "        latex_line+=\" & $\"+feature_list[i]+\"$\"\n",
    "    print(row_name+latex_line+ \"\\\\\\\\\")\n",
    "    return True\n",
    "\n",
    "def display_accuracy(accuracy_list):\n",
    "    latex_line=\"accuracy & $ fri_1 & fri_2 & fri_3 & fri_4 & chi & mi & relief \\\\\\\\\"\n",
    "    for i in range(len(accuracy_list)):\n",
    "        latex_line+=\" & $\"+str(accuracy_list[i])+\"$\"\n",
    "    print(latex_line+ \"\\\\\\\\\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 6: Features rank for FRI - chi2 - mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_features_rank(filename,number_of_random_sample):\n",
    "    dataframe = read_csv(filename,header=None,dtype=\"int\")\n",
    "    dimension=dataframe.shape[1]-1\n",
    "    size=dataframe.shape[0]\n",
    "    k_fri= int(dimension/2)  #FROM DATASET GET K VALUE  LET'S TRY 2 \n",
    "    if size > 1000:\n",
    "        ratio=0.05\n",
    "    else:\n",
    "        ratio=0.3\n",
    "    for i in range(number_of_random_sample): #creating number_of_test proper csv files\n",
    "        datatemp = dataframe.sample(frac=ratio) \n",
    "        datatemp.to_csv(\"tests/sample_\"+str(i+1)+\".csv\",index=False,header=False) \n",
    "        \n",
    "    mean_fri_scores_1  = [0]*dimension\n",
    "    mean_fri_scores_2  = [0]*dimension\n",
    "    mean_fri_scores_3  = [0]*dimension\n",
    "    mean_fri_scores_4  = [0]*dimension\n",
    "    \n",
    "    mean_chi_scores    = [0]*dimension\n",
    "    mean_mi_scores     = [0]*dimension\n",
    "    #mean_relief_scores = [0]*dimension\n",
    "    \n",
    "    for u in range(number_of_random_sample): \n",
    "        sample_file=\"tests/sample_\"+str(u+1)+\".csv\"\n",
    "        sample_set, X, y, _= load_dataset_string(sample_file)\n",
    "        set_of_pairs = all_pairs(sample_set)\n",
    "        fri_scores_1,_  = get_fri_scores(dimension,set_of_pairs,k_fri)\n",
    "        fri_scores_2,_  = get_fri_scores(dimension,set_of_pairs,k_fri+3)\n",
    "        fri_scores_3,_  = get_fri_scores(dimension,set_of_pairs,k_fri+10)\n",
    "        fri_scores_4,_  = get_fri_scores(dimension,set_of_pairs,dimension-2)  #ADDED FOR SMALL SAMPLE\n",
    "        X=X.astype(int)\n",
    "        chi_scores, _ = chi2(X, y)\n",
    "        mi_scores = mutual_info_classif(X,y,discrete_features='auto',n_neighbors=3,copy=True,random_state=None)\n",
    "       # relief_scores = relief.Relief(n_features=dimension) # we check all attributes\n",
    "       # my_transformed_matrix = relief_scores.fit_transform(X,y)\n",
    "        #relief_scores=ReliefF(n_neighbors=sample_size,n_features_to_select=10,n_jobs=-1)\n",
    "        #relief_scores.fit(X,y)\n",
    "    \n",
    "#ACCUMULATE SCORES - NO NEED TO NORMALIZE\n",
    "        for j in range(dimension):\n",
    "            mean_fri_scores_1[j]  += fri_scores_1[j]\n",
    "            mean_fri_scores_2[j]  += fri_scores_2[j]\n",
    "            mean_fri_scores_3[j]  += fri_scores_3[j]\n",
    "            mean_fri_scores_4[j]  += fri_scores_4[j]\n",
    "            \n",
    "            mean_chi_scores[j]    += chi_scores[j]\n",
    "            mean_mi_scores[j]     += mi_scores[j]\n",
    "            #mean_relief_scores[j] += relief_scores.w_[j]\n",
    "\n",
    "# GETTING AVERAGE SCORES\n",
    "    mean_fri_scores_1   = [a*(1/number_of_random_sample) for a in mean_fri_scores_1]\n",
    "    mean_fri_scores_2   = [a*(1/number_of_random_sample) for a in mean_fri_scores_2]\n",
    "    mean_fri_scores_3   = [a*(1/number_of_random_sample) for a in mean_fri_scores_3]\n",
    "    mean_fri_scores_4   = [a*(1/number_of_random_sample) for a in mean_fri_scores_4]\n",
    "    \n",
    "    mean_chi_scores     = [a*(1/number_of_random_sample) for a in mean_chi_scores]\n",
    "    mean_mi_scores      = [a*(1/number_of_random_sample) for a in mean_mi_scores]\n",
    "    #mean_relief_scores  = [a*(1/number_of_random_sample) for a in mean_relief_scores]\n",
    "\n",
    " # DISPLAYING FEATURES RANK\n",
    "    bf_fri_1  = feature_index_rank(mean_fri_scores_1)\n",
    "    bf_fri_2  = feature_index_rank(mean_fri_scores_2)\n",
    "    bf_fri_3  = feature_index_rank(mean_fri_scores_3)\n",
    "    bf_fri_4  = feature_index_rank(mean_fri_scores_4)\n",
    "    bf_chi    = feature_index_rank(mean_chi_scores)\n",
    "    bf_mi     = feature_index_rank(mean_mi_scores)\n",
    "    #bf_relief = feature_index_rank(mean_relief_scores)\n",
    "    return bf_fri_1,bf_fri_2,bf_fri_3,bf_fri_4, bf_chi,bf_mi #,bf_relief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 7: Comparing feature score effectiveness on baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASETS TO BE TESTED (in overleaf table order)\n",
    "dataset_1=\"real-datasets/covid_ready.csv\"\n",
    "dataset_2=\"real-datasets/bootcamp/bootcamp2016_ready.csv\"\n",
    "dataset_3=\"real-datasets/audio_ready.csv\"\n",
    "dataset_4=\"real-datasets/splice_ready.csv\"\n",
    "dataset_5=\"real-datasets/student_ready.csv\"\n",
    "dataset_6=\"real-datasets/bike_ready.csv\"\n",
    "\n",
    "#GET THE RANK OF FEATURES FOR ALL 7 METHODS\n",
    "#list_of_datasets=[dataset_1,dataset_2,dataset_3,dataset_4,dataset_5,dataset_6,]\n",
    "list_of_datasets=[dataset_1]\n",
    "list_of_methods=[\"fri_1\",\"fri_2\",\"fri_3\",\"fri_4\",\"chi\",\"mi\"] #,\"relief\"\n",
    "number_of_random_sample=10 #TO COMPUTE AVERAGE SCORES FOR EACH METHOD\n",
    "for dataset in list_of_datasets:\n",
    "    clean_folder(\"tests/\")\n",
    "    #INFO ON DATASET\n",
    "    size,dimension,number_of_class=get_info(dataset)\n",
    "    folds=5  #Be careful because of stratified ... if we have more than 5 classes\n",
    "    if size > 500:\n",
    "        folds=10\n",
    "    print(\"dataset_name:\",dataset,\"dimension:\", dimension,\"-- size:\",size,\"--number_of_class:\",number_of_class,\"--cross_valid:\",folds)\n",
    "    bf_fri_1,bf_fri_2,bf_fri_3,bf_fri_4, bf_chi,bf_mi=all_features_rank(dataset,number_of_random_sample)\n",
    "    list_of_ranked_features=[bf_fri_1,bf_fri_2,bf_fri_3,bf_fri_4, bf_chi,bf_mi]\n",
    "    for i in list_of_ranked_features:\n",
    "        print(i)\n",
    "    clean_folder(\"tests/\")\n",
    "#MAIN LOOP\n",
    "    for number_to_remove in [int(dimension/3),int(dimension/2),dimension-10,dimension-4,dimension-2,dimension-1]:\n",
    "        print(\"********************* dataset\"+dataset+\"*********************\")\n",
    "        print(\"** dimension:\",dimension,\" - n0 features removed:\",number_to_remove,\" - n0 features kept:\",dimension-number_to_remove,\"**\")\n",
    "        accuracy_list_lr,accuracy_list_dt, accuracy_list_rf=[],[],[]\n",
    "        for i in range(len(list_of_methods)): \n",
    "            new_file_name=\"tests/removedFeatures_\"+str(number_to_remove)+\"-\"+list_of_methods[i]+\".csv\"\n",
    "            if number_to_remove==0:\n",
    "                columns_to_remove=[]\n",
    "            else:    \n",
    "                columns_to_remove= list_of_ranked_features[i][-number_to_remove:]\n",
    "            remove_column(dataset,new_file_name,columns_to_remove)\n",
    "            data, X, y, _=load_dataset(new_file_name)\n",
    "        #acc=baseline_lr_accuracy(X, y,folds_cross_valid)\n",
    "        #accuracy_list_lr.append(round(acc,2))\n",
    "        #acc=baseline_dt_accuracy(X, y,folds_cross_valid)\n",
    "        #accuracy_list_dt.append(round(acc,2))\n",
    "            acc=baseline_rf_accuracy(X, y,folds)\n",
    "            accuracy_list_rf.append(round(acc,2))\n",
    "        #display_accuracy(accuracy_list_lr)\n",
    "        #display_accuracy(accuracy_list_dt)\n",
    "        display_accuracy(accuracy_list_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
